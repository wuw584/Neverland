{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../czyc/test3/czyc_3km_GL_10m_frq_1kHz_sp_2m_UTC_20240103_140512.357.h5 ../../czyc/test3/czyc_3km_GL_10m_frq_1kHz_sp_2m_UTC_20240105_061712.357.h5\n"
     ]
    }
   ],
   "source": [
    "# last modified 2024/4/24 \n",
    "# %matplotlib ipympl\n",
    "%matplotlib inline\n",
    "import h5py \n",
    "import glob\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from DasTools import DasPrep as dp\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib\n",
    "import logging\n",
    "import csv\n",
    "import time\n",
    "def concat(flist , start = 0 , span = 20  ):\n",
    "    datalist = []\n",
    "    for fname in flist[ start : start + span ]:\n",
    "        data = dp.read_das(fname)\n",
    "        datalist.append(data)\n",
    "\n",
    "    data = np.concatenate(datalist, axis = 1)\n",
    "    utc_datetime = datetime.datetime.strptime(flist[start][-22 : -7],'%Y%m%d_%H%M%S') + datetime.timedelta(hours=+8)\n",
    "    utc_day = utc_datetime.strftime(\"%m-%d %H:%M\")\n",
    "    print(\"cat\")\n",
    "    return data , utc_datetime, utc_day \n",
    "\n",
    "\n",
    "def psd(startn,endn):\n",
    "    # 创建一个dataset\n",
    "    span_each_pic = 10 #12h -> 50min\n",
    "    concat_time = 0\n",
    "    psd_time = 0\n",
    "    all_start = time.time()\n",
    "\n",
    "    ch_list = [20*i for i in range(148)]\n",
    "    for n in range(startn, endn):\n",
    "        data , utc_datetime, utc_day = concat(flist , start= span_each_pic * n ,span= span_each_pic)\n",
    "        nfft = 30000\n",
    "        fs = 2000\n",
    "        start = time.time()\n",
    "\n",
    "\n",
    "        for i in range(len(ch_list)):\n",
    "            with h5py.File('../output/DAS/psd_5_11/test2_ch'+str(ch_list[i])+'.hdf5', 'a') as f:\n",
    "                # g =  f.create_group(str(ch_list[i]))  \n",
    "                [f1,Pxx1] = signal.welch(data[i],                   # 随机信号\n",
    "                                nfft=nfft,               # 每个窗的长度\n",
    "                                fs=fs,                   # 采样频率   \n",
    "                                # detrend='mean',          # 去掉均值\n",
    "                                window=np.hanning(nfft), # 加汉尼窗\n",
    "                                noverlap=int(nfft*3/4),  # 每个窗重叠75%的数据\n",
    "                                )        # 求单边谱\n",
    "                # print(f1)\n",
    "                f.create_dataset(str(utc_day),  data=Pxx1 , chunks=len(Pxx1))\n",
    "                f.close()\n",
    "\n",
    "        concat_time +=  time.time() -start\n",
    "        all_time = time.time() -all_start\n",
    "        print(n , \"psd运行时间:%.2f min %d s\"%( int(concat_time / 60) , concat_time%60)+\"/ all :%.2f min %d s\"%( int(all_time / 60) , all_time%60) , utc_day, \"check in \")\n",
    "\n",
    "flist = glob.glob('../../czyc/test3/*357.h5')\n",
    "flist.sort()\n",
    "print(flist[0] ,flist[-1])\n",
    "\n",
    "# path = '../output/DAS/psd_5_11/'\n",
    "# if not os.path.exists(path):\n",
    "#     os.makedirs(path)\n",
    "\n",
    "# print(int(len(flist)/10))\n",
    "\n",
    "# flist = flist[:]\n",
    "\n",
    "# psd(startn=642 , endn=667) #10 chunk 14min \n",
    "# #642-1204 psd运行时间:157.00 min 1 s/ all :617.00 min 50 s 01-01 20:45 check in \n",
    "\n",
    "# 537"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log\n",
    "5.9 周四 罗老师和袁师兄\n",
    "1.das Hz time 在30 40 50道 1.5晚上0-9点 低频部分有类似多普勒效应的能量，可以做stft放大清晰度。实现提示：十倍十倍地放大缩小窗长 以提高清晰度，重叠50%，\n",
    "2.das Hz time 在30 40 50道 能量暴增前期  有一个有类似多普勒效应的能量，可以做stft放大清晰度。实现提示：十倍十倍地放大缩小窗长 以提高清晰度，重叠50%，\n",
    "\n",
    "3.psd 主要是反应平稳信号 去掉噪声\n",
    "4. 740道有局部异常，1.5 8-10点的信号有暴增，可以往前多画几天看看是否是规律人类活动，但是发现传播方向既不是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "test3_ch 20   (54, 253124) (432,)\n",
      "运行时间 all :0.00 min 42 s\n",
      "test3_ch 23   (54, 253124) (432,)\n",
      "运行时间 all :1.00 min 27 s\n",
      "test3_ch 26   (54, 253124) (432,)\n",
      "运行时间 all :1.00 min 56 s\n",
      "test3_ch 29   (54, 253124) (432,)\n",
      "运行时间 all :2.00 min 27 s\n",
      "test3_ch 32   (54, 253124) (432,)\n",
      "运行时间 all :2.00 min 53 s\n",
      "test3_ch 35   (54, 253124) (432,)\n",
      "运行时间 all :3.00 min 18 s\n",
      "test3_ch 38   (54, 253124) (432,)\n",
      "运行时间 all :3.00 min 44 s\n",
      "test3_ch 41   (54, 253124) (432,)\n",
      "运行时间 all :4.00 min 10 s\n",
      "test3_ch 44   (54, 253124) (432,)\n",
      "运行时间 all :4.00 min 37 s\n",
      "test3_ch 47   (54, 253124) (432,)\n",
      "运行时间 all :5.00 min 2 s\n",
      "test3_ch 50   (54, 253124) (432,)\n",
      "运行时间 all :5.00 min 27 s\n",
      "test3_ch 53   (54, 253124) (432,)\n",
      "运行时间 all :5.00 min 51 s\n",
      "test3_ch 56   (54, 253124) (432,)\n",
      "运行时间 all :6.00 min 19 s\n",
      "test3_ch 59   (54, 253124) (432,)\n",
      "运行时间 all :6.00 min 44 s\n"
     ]
    }
   ],
   "source": [
    "import DasBatch as db\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# flist = glob.glob('../../czyc/test3/*357.h5')\n",
    "# flist.sort()\n",
    "# print(len(flist))\n",
    "\n",
    "# path = '../output/DAS/stft_5_12/'\n",
    "# if not os.path.exists(path):\n",
    "#     os.makedirs(path)\n",
    "\n",
    "# index_start =flist.index('../../czyc/test3/czyc_3km_GL_10m_frq_1kHz_sp_2m_UTC_20240104_070012.357.h5')\n",
    "# index_end =flist.index('../../czyc/test3/czyc_3km_GL_10m_frq_1kHz_sp_2m_UTC_20240104_160012.357.h5')\n",
    "# print(flist[0] , index_start , index_end)\n",
    "\n",
    "# # index_end =flist.index('../../czyc/test3/czyc_3km_GL_10m_frq_1kHz_sp_2m_UTC_20240105_010012.357.h5')\n",
    "\n",
    "# span_each_pic = 20\n",
    "# print(index_start,index_end )\n",
    "\n",
    "# ch_list = [20+i for i in range(40)]\n",
    "# db.das_time2ch(flist , ch_list , \n",
    "#                index_start ,  index_end  ,step= 10 , \n",
    "#                save_path= \"../output/DAS/das_as_channel_5_14/test3_ch \") #大概30min\n",
    "\n",
    "\n",
    "flist = glob.glob('../output/DAS/das_as_channel_5_14/test3_ch*')\n",
    "flist.sort()\n",
    "print(len(flist))\n",
    "\n",
    "path = \"../output/DAS/das_as_channel_5_14/fig5/\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "\n",
    "# db.cal_and_show_stft(flist= flist ,\n",
    "#                   title = \"czyc\",\n",
    "#                   save_path = path,\n",
    "#                   fs=1000 ,  nperseg= 1024 , overlap= 512) #大概\n",
    "\n",
    "db.cal_and_show_stft_split(flist= flist[::3] ,\n",
    "                  title = \"czyc\",\n",
    "                  save_path = \"../output/DAS/das_as_channel_5_14/fig9/\",\n",
    "                  split = 18,\n",
    "                  figsize0= [30,12],\n",
    "                  fs=1000 ,  nperseg= 512 , overlap= 256) #大概\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2024-01-04 15:00:12', '2024-01-04 15:02:42', '2024-01-04 15:05:12', '2024-01-04 15:07:42', '2024-01-04 15:10:12', '2024-01-04 15:12:42', '2024-01-04 15:15:12', '2024-01-04 15:17:42']\n"
     ]
    }
   ],
   "source": [
    "import DasBatch as db\n",
    "import glob\n",
    "import os\n",
    "import scipy\n",
    "def channel_2_wav(flist , save_path , fs ,  start_time = None  ,end_time =None ):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for fname in flist:\n",
    "\n",
    "        with h5py.File(fname, 'r') as f:\n",
    "            time_list = [key for key in f.keys()]\n",
    "            print(time_list[:8])\n",
    "            if start_time is not None and end_time is not None : \n",
    "                    time_list = time_list[time_list.index(start_time):time_list.index(end_time)+1]\n",
    "            data= [f[key][:] for key in time_list][:]\n",
    "            data = np.concatenate(data)\n",
    "            ch = fname.split('/' )[-1][:-5]\n",
    "            scipy.io.wavfile.write(save_path+ch+\".wav\" , fs ,data)\n",
    "\n",
    "channel_2_wav(flist=[\"../output/DAS/das_as_channel_5_14/test3_ch 26.hdf5\"],\n",
    "              start_time='2024-01-05 01:07:42',\n",
    "              end_time='2024-01-05 01:37:42',\n",
    "              fs= 150000,\n",
    "              save_path= \"../output/DAS/das_as_channel_5_14/wav/\")   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些需要关注的\n",
    "从hdf5中读取需要看看是分通道保存还是分时间保存，\n",
    "计算时选取整10分钟的点位开始，计算时长也要符合，以方便画图\n",
    "其次，作图时应该考虑分天数画图，如果超过36小时\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------read 1200 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1220 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1240 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1260 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1280 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1300 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1320 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1340 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1360 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1380 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1400 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1420 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1440 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1460 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1480 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1500 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1520 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1540 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1560 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1580 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1600 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1620 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1640 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1660 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1680 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1700 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1720 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1740 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1760 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1780 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1800 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1820 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n",
      "-----------read 1840 ------------\n",
      "(667, 15001)\n",
      "(667, 7502)\n"
     ]
    }
   ],
   "source": [
    "import h5py \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "def channel_chunk_show_psd_Hz_time_split(psd_path ,ch_list, frequencise, title ,save_path , timeshift = None , split = None , time_ticks = 15):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for ch in ch_list:\n",
    "        psd = []\n",
    "        all_time = []\n",
    "        with h5py.File(psd_path+str(ch)+'.hdf5', 'r') as f:\n",
    "            \n",
    "            time = [key for key in f.keys()]\n",
    "            #日期的排序和字符排序问题\n",
    "            if timeshift is not None:\n",
    "                start = time.index(timeshift)\n",
    "                time = time[start:]+time[:start]\n",
    "            psd.append([f[key][:] for key in time])\n",
    "            all_time.append(time[:])\n",
    "            f.close()\n",
    "        print(\"-----------read\",ch,\"------------\")\n",
    "        psd = np.concatenate(psd)\n",
    "        time = np.concatenate(all_time)\n",
    "        print(psd.shape)\n",
    "        flim= len(psd[0])//2+2\n",
    "        psd = psd[: , :flim]\n",
    "        \n",
    "        psd = np.log(psd)\n",
    "        print(psd.shape)\n",
    "\n",
    "        psdlist = np.array_split(psd , split ,axis=0)\n",
    "        timelist = np.array_split(time ,split)\n",
    "\n",
    "        for i in range(split):\n",
    "            psdi = psdlist[i]\n",
    "            timei = timelist[i]\n",
    "            \n",
    "            plt.figure(figsize=(30,10))\n",
    "            plt.imshow(psdi.T, aspect='auto', cmap='jet',vmin=0, vmax=12)\n",
    "            plt.grid(alpha = 1)\n",
    "\n",
    "            timei_show = range(0 , len(timei) , time_ticks )\n",
    "            \n",
    "            plt.xticks(timei_show , [timei[t][-8:] for t in timei_show],rotation = 0)\n",
    "\n",
    "            plt.yticks(np.linspace(0 , len(psdi[0])  , 11 ), np.linspace(0,fs/2 , 11 ,dtype=np.int16))\n",
    "            plt.ylabel(\"Frequency(Hz)\")\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.title(title+\" Channel=\"+str(ch))\n",
    "\n",
    "            plt.colorbar()\n",
    "            plt.savefig(save_path+'ch_'+str(ch)+\" \" +str(i)+'_psd_.png') #10s per pic\n",
    "            plt.close()\n",
    "\n",
    "fs = 1000\n",
    "db.channel_chunk_show_psd_Hz_time_split(psd_path='../output/DAS/psd_5_12/test2_ch',\n",
    "                 ch_list = range(1200,1841,20),\n",
    "                 frequencise=[fs/4],\n",
    "                 timeshift=\"12-30 21:55\",\n",
    "                 save_path='../output/DAS/psd_5_12/fig2/' ,\n",
    "                 split=2,\n",
    "                 title= \"czyc test2 nfft = 30000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------read 1200 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1220 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1240 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1260 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1280 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1300 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1320 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1340 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1360 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1380 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1400 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1420 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1440 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1460 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1480 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1500 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1520 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1540 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1560 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1580 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1600 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1620 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1640 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1660 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1680 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1700 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1720 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1740 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1760 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1780 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1800 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1820 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n",
      "-----------read 1840 ------------\n",
      "(564, 15001)\n",
      "(564, 7502)\n"
     ]
    }
   ],
   "source": [
    "fs = 1000\n",
    "channel_chunk_show_psd_Hz_time_split(psd_path='../output/DAS/psd_5_11/test2_ch',\n",
    "                 ch_list = range(1200,1841,20),\n",
    "                 frequencise=[fs/4],\n",
    "                #  timeshift=\"12-30 21:55\",\n",
    "                 save_path='../output/DAS/psd_5_11/fig3/' ,\n",
    "                 split=2,\n",
    "                 title= \"czyc test2 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DasBatch as db\n",
    "# path = '../output/DAS/stft_5_12/fig/'\n",
    "# if not os.path.exists(path):\n",
    "#     os.makedirs(path)\n",
    "\n",
    "# flist = glob.glob('../output/DAS/stft_5_12/test3_ch*.hdf5')\n",
    "# flist.sort()\n",
    "# print(len(flist))\n",
    "# db.show_stft_time(flist=flist , \n",
    "#                ft='../output/DAS/stft_5_12/test3_ft.hdf5',\n",
    "#                ch_list= range(0,2941 , 20) ,\n",
    "#                start_time= \" \" , \n",
    "#                end_time=\" \" , \n",
    "#                title= \"czyc test2  \",\n",
    "#                save_path=path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hi，有个新的想法。把创智云城psd做一个傅里叶反变换，就是自相关函数。然后画出来自相关函数随通道变化的热度图，可以试试能不能看地下结构信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "589145a86ff47c0702b9b07b1f1ea869940002b58fc6d81363634b7541cd255b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
